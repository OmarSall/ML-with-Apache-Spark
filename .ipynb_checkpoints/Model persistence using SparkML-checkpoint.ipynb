{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba0553",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark==3.1.2 -q\n",
    "!pip install findspark -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920307e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# FindSpark simplifies the process of using Apache Spark with Python\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "#import functions/Classes for sparkml\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# import functions/Classes for metrics\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399c38fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create SparkSession\n",
    "#Ignore any warnings by SparkSession command\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Model Persistence\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4391593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/mpg.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49479d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the spark.read.csv function we load the data into a dataframe.\n",
    "# the header = True mentions that there is a header row in out csv file\n",
    "# the inferSchema = True, tells spark to automatically find out the data types of the columns.\n",
    "\n",
    "# Load mpg dataset\n",
    "mpg_data = spark.read.csv(\"mpg.csv\", header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bac7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e991fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare feature vector\n",
    "assembler = VectorAssembler(inputCols=[\"Cylinders\", \"Engine Disp\", \"Horsepower\", \"Weight\", \"Accelerate\", \"Year\"], outputCol=\"features\")\n",
    "mpg_transformed_data = assembler.transform(mpg_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a27fe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_transformed_data.select(\"features\",\"MPG\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49525ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "(training_data, testing_data) = mpg_transformed_data.randomSplit([0.7, 0.3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455abbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train linear regression model\n",
    "# Ignore any warnings\n",
    "lr = LinearRegression(labelCol=\"MPG\", featuresCol=\"features\")\n",
    "pipeline = Pipeline(stages=[lr])\n",
    "model = pipeline.fit(training_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710188a2",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec79dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir model_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43816039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist the model to the path \"./model_stoarage/\"\n",
    "\n",
    "model.write().overwrite().save(\"./model_storage/\")\n",
    "\n",
    "#The overwrite method is used to overwrite the model if it already exists,\n",
    "#and the save method is used to specify the path where the model should be saved.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb40dd3f",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5d7df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.pipeline import PipelineModel\n",
    "\n",
    "# Load persisted model\n",
    "loaded_model = PipelineModel.load(\"./model_storage/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2869f768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "predictions = loaded_model.transform(testing_data)\n",
    "#In the above example, we use the load method of the PipelineModel object to load the persisted model from disk. We can then use this loaded model to make predictions on new data using the transform method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0401ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on testing data\n",
    "predictions = model.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e46771",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.select(\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b41e8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db95e19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
